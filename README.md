# Persian_word2vec 
Word2vec is one of the embedding methods in NLP. Here we prepared a Persian word2vec model simply :)
actually, we did it with the Gensim library. The model has millions of words in thousands of sentences. 
First we made a word2vec model in [word2vec1.ipynb](https://github.com/m0javad/Persian_word2vec/blob/main/word2vec1.ipynb) then we substituted the words in a sentence with the most similar for each word from the prepared model (mostly used in paraphrase, blindly) in [word2vec2.ipynb](https://github.com/m0javad/Persian_word2vec/blob/main/word2vec2.ipynb).
you can make your own word2vec embedding with these codes and if you want to use a ready Persian model put word2vec.z01 and word2vec.z02 in a folder then unzip them. I trained the Model with 10 milions sentences.

DO NOT FORGET TO GET STAR IF YOU USE THIS REPO. GOODLUCK
